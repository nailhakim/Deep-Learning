{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QAhKMQIK93hU"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
        "print(df.head())\n",
        "print(\"Jumlah data:\", len(df))"
      ],
      "metadata": {
        "id": "tEDe7R3d9-yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil fitur dan label\n",
        "texts = df['headline'].values\n",
        "labels = df['is_sarcastic'].values\n",
        "\n",
        "# Parameter tokenisasi\n",
        "max_vocab =\n",
        "max_length =\n",
        "\n",
        "# Tokenisasi\n",
        "tokenizer = Tokenizer(num_words=max_vocab, oov_token='')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "print(\"Ukuran train:\", X_train.shape, \"Ukuran test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "mmQdY3QF-BX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter umum\n",
        "embedding_dim =\n",
        "units =\n",
        "drop_rate =\n",
        "\n",
        "def create_rnn_model():\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_lstm_model():\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_gru_model():\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1zlpFbVB-Meb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =\n",
        "batch_size =\n",
        "\n",
        "# Buat dan latih model RNN\n",
        "rnn_model = create_rnn_model()\n",
        "history_rnn = rnn_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_split=0.1, verbose=1)\n",
        "rnn_loss, rnn_acc = rnn_model.evaluate(X_test, y_test)\n",
        "print(\"RNN Test Accuracy:\", rnn_acc)\n",
        "\n",
        "# Buat dan latih model LSTM\n",
        "lstm_model = create_lstm_model()\n",
        "history_lstm = lstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                              validation_split=0.1, verbose=1)\n",
        "lstm_loss, lstm_acc = lstm_model.evaluate(X_test, y_test)\n",
        "print(\"LSTM Test Accuracy:\", lstm_acc)\n",
        "\n",
        "# Buat dan latih model GRU\n",
        "gru_model = create_gru_model()\n",
        "history_gru = gru_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                            validation_split=0.1, verbose=1)\n",
        "gru_loss, gru_acc = gru_model.evaluate(X_test, y_test)\n",
        "print(\"GRU Test Accuracy:\", gru_acc)"
      ],
      "metadata": {
        "id": "7wXCL9gL-Ox7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk plot\n",
        "def plot_history(histories, metric='accuracy'):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for name, history in histories.items():\n",
        "        plt.plot(history.history[metric], label=f'{name} Train')\n",
        "        plt.plot(history.history['val_' + metric], label=f'{name} Val')\n",
        "    plt.title(f'Model {metric.capitalize()}')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "histories = {'RNN': history_rnn, 'LSTM': history_lstm, 'GRU': history_gru}\n",
        "plot_history(histories, metric='accuracy')\n",
        "plot_history(histories, metric='loss')"
      ],
      "metadata": {
        "id": "2I3Efpzj-R3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}